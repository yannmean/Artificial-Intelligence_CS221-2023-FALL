{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yannmean/Artificial-Intelligence_CS221-2023-FALL/blob/main/OngigModels_YM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuorzWydQHKM"
      },
      "source": [
        "# 0. House keeping\n",
        "\n",
        "This section is mainly for setting up the environment, installing and loading packages, setting up the working directly on Google Drive.\n",
        "\n",
        "Please note that colab is make for python by default, but I created a R environment within (some people call it \"the r magic\"). So the codes are still written in R. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhgvfqwaNxQ-",
        "outputId": "a8ad9288-ba59-4fe4-eb8b-c16553f05576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Ongig\n",
            "adverbsCounts.csv\t\t\tjobPostWordVector.pdf\n",
            "adverbs.csv\t\t\t\tOngig_Colab\n",
            "adverb-weight-dataset.csv\t\tridgeAdvCoefs.csv\n",
            "adverb-weight-dataset_newAdvScores.csv\n"
          ]
        }
      ],
      "source": [
        "# Mount to my googled drive directory which contains the original dataset, and the ridge coefficients\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Here I created this directory in my google drive to host all the objects needed for this computation\n",
        "%cd /content/drive/MyDrive/Ongig/ \n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wSbJ9VcNI0Q5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# activate R in python console\n",
        "!pip install rpy2==3.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IKz3X-GCNm0L"
      },
      "outputs": [],
      "source": [
        "# Load R environment\n",
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTZLXLg2PMi_"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# install and load necessary packages and load from library\n",
        "\n",
        "install.packages(\"dplyr\")\n",
        "install.packages(\"reshape\")\n",
        "install.packages(\"ggplot2\")\n",
        "install.packages(\"tidyr\")\n",
        "\n",
        "pkgs <- c(\"dplyr\", \"reshape\", \"ggplot2\", \"tidyr\")\n",
        "sapply(pkgs, require, character.only = T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQRd_CBI_0do"
      },
      "source": [
        "# 1. Compute the Adverb Score\n",
        "\n",
        "## 1.1 Introduction \n",
        "To obtain the adverb score for one job posting, we need the following three components: \n",
        "\n",
        "1) the weight of each adverb that exist in this job posting;\\\n",
        "2) the number of times each adverb has appeared in the same job posting;\\\n",
        "3) the total number of adverbs in the same job posting\n",
        "\n",
        "The first component - weight of each adverb - has been obtained via a statistical learning method, ridge regression, and stored as a dataframe of two variables: \n",
        "\n",
        "*   advScore - the weight (stored as float)\n",
        "*   adv - the adverbs (stored as string)\n",
        "\n",
        "The second component - adverb frequency in each job posting - has been obtained by counting the number of each adverb that appeared in a given job posting.\n",
        "\n",
        "Finally, the third component - total number of adverbs - is calculated by counting the total number of adverbs (if one adverb appeared twice, we count it as 2, instead of 1.)\n",
        "\n",
        "## 1.2 Adverb Score Construction\n",
        "\n",
        "First, let's clarify the notations \n",
        "\n",
        "\n",
        "*   Let $s_i$ be the adverb score for job posting $i$\n",
        "*   Let $w_j$ be the ridge coefficient of adverb $j$ (a.k.a. the \"weight\")\n",
        "*   Let $n_{ij}$ be the frequency count of adverb $j$ in job posting $i$\n",
        "*   Let $N_i$ be the total number of adverbs in job posting $i$\n",
        "\n",
        "Therefore, the adverb score of job posting j can be calculated as the following:\n",
        "\n",
        "\\begin{align}\n",
        " s_i = \\sum_{j} w_j \\frac{n_{ij}}{N_i} \n",
        "\\end{align}\n",
        "\n",
        "In other words, the adverb score is the sum of the weighted adverb frequencies of the adverbs that are from the job posting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1KJd0-pHRh1"
      },
      "source": [
        "## 1.3 Data Preparation for Computation\n",
        "In the actual computation, we will not compute the adverb score for each job posting one-by-one, as this is not efficient and will take too long when we have millions of adverb scores that we would like to compute. Rather we formulate the computation into a Hadamard product of two matrices (element-wise multiplication), hence the computation is much faster. \n",
        "\n",
        "### 1.3.1 First, we need to prepare our dataset by creating the adverb frequency table by parsing, counting adverbs for each posting. \n",
        "\n",
        "There are three objects which need to be pre-loaded:\n",
        "*   The original dataset (adverb-weight-dataset.csv)\n",
        "*   The master adverb list from Ongig (adverbs.csv)\n",
        "*   The adverb weights (ridgeAdvCoefs.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "RLSJFOBHCCOz",
        "outputId": "9ac55b48-299c-4a93-9e02-95c135a144bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "RInterpreterError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;31m# Need the newline in case the last line in code is a comment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"withVisible({%s\\n})\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_k\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         return (super(SignatureTranslatedFunction, self)\n\u001b[0m\u001b[1;32m    202\u001b[0m                 .__call__(*args, **kwargs))\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/robjects/functions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy2rpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror_occured\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geterrmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRRuntimeError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-83d8aa2cd2d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# load the original dataset\\ndf <- read.csv(\"adverb-weight-dataset.csv\")\\n\\n# load the master list of adverbs\\nadvList <- read.csv(\"adverbs.csv\", header = F)\\n\\n# load the adverb weights\\nridge_weights <- read.csv(\"ridgeAdvCoefs.csv\")\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-122>\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0mreturn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                 \u001b[0mtext_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mtext_output\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtext_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;31m# Otherwise next return seems to have copy of error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mwarning_or_other_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 raise RInterpreterError(code, str(exception),\n\u001b[0m\u001b[1;32m    285\u001b[0m                                         warning_or_other_msg)\n\u001b[1;32m    286\u001b[0m             \u001b[0mtext_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line '# load the original dataset\\ndf <- read.csv(\"adverb-weight-dataset.csv\")\\n\\n# load the master list of adverbs\\nadvList <- read.csv(\"adverbs.csv\", header = F)\\n\\n# load the adverb weights\\nridge_weights <- read.csv(\"ridgeAdvCoefs.csv\")\\n'.\nR error message: ''"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# load the original dataset\n",
        "df <- read.csv(\"adverb-weight-dataset.csv\")\n",
        "\n",
        "# load the master list of adverbs\n",
        "advList <- read.csv(\"adverbs.csv\", header = F)\n",
        "\n",
        "# load the adverb weights\n",
        "ridge_weights <- read.csv(\"ridgeAdvCoefs.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qyM4TeMOipv"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# subset the dataset to only include \"job_id\" and \"adverbs\"\n",
        "df_adv <- df[, c(\"job_id\", \"adverbs\")] \n",
        "df_adv$adverbs <- gsub(\" \", \"\", df_adv$adverbs)\n",
        "# note the largest number of adverbs that one posting has is 64.\n",
        "df_adv <- df_adv %>% separate(adverbs, paste0(\"adv\", c(1:64)), sep = \",\", remove = T)\n",
        "\n",
        "# obtain adverbs from the current job posting\n",
        "adverbsFromPosting <- unique(as.vector(as.matrix(df_adv[,2:ncol(df_adv)])))\n",
        "adverbsFromPosting <- adverbsFromPosting[adverbsFromPosting!= \"\" & !is.na(adverbsFromPosting)] \n",
        "\n",
        "# create a data frame to hold adverb frequencies for each job posting\n",
        "df_advCounts <- data.frame(matrix(0, ncol = nrow(advList) + 1, nrow = nrow(df)))\n",
        "colnames(df_advCounts) <- c(\"job_id\", advList$V1)\n",
        "\n",
        "# this step might take 1 minute or 2 \n",
        "for (i in 1:nrow(df_adv)) {\n",
        "  df_advCounts[i, \"job_id\"] = df_adv$job_id[i]\n",
        "  df_adv_temp <- df_adv[i,]\n",
        "  df_adv_temp <- df_adv_temp[!is.na(df_adv_temp)]\n",
        "  \n",
        "  # inner loop start from the second index as the first index is the job_id\n",
        "  for (j in 2:length(df_adv_temp)) {\n",
        "    col_index <- which(colnames(df_advCounts) == df_adv_temp[j])\n",
        "    df_advCounts[i, col_index] <-  df_advCounts[i, col_index] + 1  \n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI6v1_bfTd4N"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# df_advCounts dataframe contains all the adverbs, however there are many adverbs \n",
        "# from the master adverb lists do not exist in current job postings, here we only\n",
        "# keep the adverbs that have appeared in the current job postings. \n",
        "df_advCounts <- df_advCounts[, colnames(df_advCounts) %in% adverbsFromPosting]\n",
        "df_advCounts$job_id <- df_adv$job_id\n",
        "\n",
        "# compute the total number of adverbs in each job posting, and store that value in variable \"advTotal\"\n",
        "df_advCounts$advTotal <- rowSums(df_advCounts[, !names(df_advCounts) %in% c(\"job_id\", \"advTotal\")])\n",
        "\n",
        "# sanity check the dimension of this dataframe, the number of colum should be 534 adverbs + job_id + adv_total\n",
        "dim(df_advCounts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct_Sec5tTyTc"
      },
      "source": [
        "### 1.3.2 We store a version of the adverb frequency table for future use. (In case this session is timed-out, we also don't have to reconstruct it.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZzwG_M1Tx_7"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Now that this dataset should be saved in the google drive folder\n",
        "write.csv(df_advCounts, file = \"/content/drive/MyDrive/Ongig/adverbsCounts.csv\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5npHIxdpaW8r"
      },
      "source": [
        "### 1.3.3 Now we need to make sure the ridge_weights matrix (the weight matrix) and the df_advCounts matrix (the frequency matrix) have the same dimension, and all adverbs are following the same orders along the column. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW3ri92WZ-tX"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# obtain the number of job postings we have\n",
        "n = nrow(df_advCounts)\n",
        "\n",
        "# we broadcast the ridge_weights following the dimension of the adverb frequency matrix, df_advCounts\n",
        "ridge_weights_expand <- cbind(ridge_weights, rep(ridge_weights[2], each = n)) %>% t() %>% as.data.frame()\n",
        "ridge_weights_expand <- ridge_weights_expand[3:nrow(ridge_weights_expand), 3:ncol(ridge_weights_expand)] \n",
        "colnames(ridge_weights_expand) <- ridge_weights_expand[1,]\n",
        "ridge_weights_expand <- ridge_weights_expand[-1,]\n",
        "ridge_weights_expand <- ridge_weights_expand[,!colnames(ridge_weights_expand) %in% c(\"job_id\", \"advTotal\")]\n",
        "# sanity check the dimension of ridge_weights_expand\n",
        "dim(ridge_weights_expand)\n",
        "\n",
        "# re-order the columns to make sure adverbs in the weight matrix follow the same order\n",
        "ridge_weights_expand <- ridge_weights_expand[, order(colnames(ridge_weights_expand))] \n",
        "\n",
        "ridge_weights_expand <- as.matrix(sapply(ridge_weights_expand, as.numeric))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5THR-BsQciLM"
      },
      "source": [
        "### 1.3.4 Now make sure the frequency matrix is having the same dimension and the same adverb ordering as the weight matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewwl3-p_a4hC"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# First double check that all adverbs from df_advCounts are included in the weight matrix\n",
        "df_advCounts <- df_advCounts[,colnames(df_advCounts) %in% colnames(ridge_weights_expand) & ! colnames(df_advCounts) %in% c(\"job_id\", \"advTotal\")]\n",
        "\n",
        "# make sure the adverbs follow the same order\n",
        "df_advCounts <- df_advCounts[, order(colnames(df_advCounts))]\n",
        "\n",
        "df_advCounts <- as.matrix(sapply(df_advCounts, as.numeric))\n",
        "# sanity check of the dimension \n",
        "dim(df_advCounts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BJY088biE-F"
      },
      "source": [
        "## 1.4 Adverb Score Computation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRq36VJSiEol"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Step 1. compute the Hadamard product of the weight matrix and the frequency matrix (element-wise products) \n",
        "# call this the adverb raw score\n",
        "advRawScores <- ridge_weights_expand * df_advCounts \n",
        "\n",
        "# sanity check for dimention\n",
        "dim(advRawScores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYZ1uLxXjLj-"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Step 2. compute the sum of the raw scores\n",
        "advRawScoresSum <- rowSums(advRawScores)\n",
        "\n",
        "# Step 3. reweight the raw score by the total number of advs \n",
        "advScoresNew <- advRawScoresSum/rowSums(df_advCounts)\n",
        "\n",
        "# Step 4. set the advScoresNew as 0 for those postings without any adverbs\n",
        "advScoresNew[is.na(advScoresNew)] = 0\n",
        "\n",
        "# Step 5. merge the new score back into the original dataset for future use\n",
        "df$advScoresNew <- advScoresNew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXRlP-hP5dFj"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# save a version of the updated dataset\n",
        "write.csv(df, file = \"/content/drive/MyDrive/Ongig/adverb-weight-dataset_newAdvScores.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnmZT7V4jXj3"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Vistualizee the distribution of the new adverb score\n",
        "ggplot(df, aes(x = advScoresNew)) + geom_histogram(bins = 100) + theme_classic() + ggtitle(\"Distribution of New Adverb Score From Ridge Regression\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "av2mdqfK9_c7"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Vistualizee the distribution again, but removing all the zeros\n",
        "ggplot(df[df$advScoresNew!=0,], aes(x = advScoresNew)) + geom_histogram(bins = 100) + theme_classic() + ggtitle(\"Distribution of New Adverb Score (Non-zero) From Ridge Regression\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggu-g7XBLqpo"
      },
      "source": [
        "## 1.5 Rescale the new adver score to 0 to 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUaZIbZCL2Rb"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# reload the previously safe the dataset if the session logs out. \n",
        "# df <- read.csv(\"/content/drive/MyDrive/Ongig/adverb-weight-dataset_newAdvScores.csv\")\n",
        "\n",
        "as <- df$advScoresNew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1LFesNyM_Vc"
      },
      "source": [
        "### 1.5.1 arctan transformation \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Jr53S1_NGC8"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# scale by 100 so that arctan (x) is more spread across the whole range pf -3.14/2, 3.14/2\n",
        "as_arctan <- atan(as*100) \n",
        "summary(as_arctan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK7G8IPNN-r4"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "hist(as_arctan, breaks = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_Kvqw5JNKaq"
      },
      "source": [
        "### 1.5.2 compute z score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5TI__rCNTXE"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "mean <- mean(as_arctan)\n",
        "sd <- sd(as_arctan)\n",
        "as_arc_z <- (as_arctan - mean) / sd\n",
        "summary(as_arc_z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1raGJ7KiN4Sv"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "hist(as_arc_z, breaks = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgxuFO5LNaDA"
      },
      "source": [
        "### 1.5.3 shift the distribution from range (-$\\pi$/2, $\\pi$/2), to (0, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kdUNw9FNpqJ"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# by symmmetry, the mean of a symmetric distribution on (0, 100) should be 50\n",
        "as_rescaled <- 50 + as_arc_z*(sd*30) # rescale sd by 30 to spread on the new domain\n",
        "summary(as_rescaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swZhMA7zOGI1"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "hist(as_rescaled, breaks = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPWQUqOvOMij"
      },
      "source": [
        "### 1.5.4 for those smaller than zero are set at zero, larger than 100 are set at 100 (didn't happen in our current case), it might happen in future with very small probability (4 standard deviation from the mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUIPTU_GOWIn"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "as_rescaled[as_rescaled < 0] = 0\n",
        "as_rescaled[as_rescaled > 100] = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_HKPzo2OYPI"
      },
      "source": [
        "### 1.5.5 testing and evaluation the new rescaled adv score:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YpbrPRrOn_m"
      },
      "source": [
        "#### create variables needed for the evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7xCfoWDOfL-"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "df$as_rescaled <- as_rescaled\n",
        "df$unique_apply_rate <- df$unique_applystarts / df$unique_views\n",
        "df$word_count_sqr <- df$word_count * df$word_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y11wFJArOr3m"
      },
      "source": [
        "#### examine correlation betweent rescaled and the unscaled new adverb score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjsR6BP1Orgg"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "cor(df$advScoresNew, df$as_rescaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij5jjlSBO1Qv"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "plot(df$advScoresNew, df$as_rescaled) # monotonic transformation, sigma curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh-nJhfzPG6R"
      },
      "source": [
        "#### predicting the outcome - unique application rate (uptake), compared with the new adverb score that hasn't been rescaled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQq-tkXpPME_"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "lm_new_adv_score <- lm(unique_apply_rate ~ advScoresNew + word_count + word_count_sqr + title + title*advScoresNew, data = df)\n",
        "lm_new_adv_score_rescale <- lm(unique_apply_rate ~ as_rescaled + word_count + word_count_sqr + title + title*as_rescaled, data = df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlzsJfHZPYyK"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# new adverb score (unscaled)\n",
        "summary(lm_new_adv_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgmxbPHYQZ_k"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# new adverb score (rescaled)\n",
        "summary(lm_new_adv_score_rescale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6TJ0TNYQhMV"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# anova on new adverb score (unscaled)\n",
        "anova(lm_new_adv_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPJITpG5QnLA"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# anova on new adverb score (rescaled)\n",
        "anova(lm_new_adv_score_rescale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFk-ChHhBsdn"
      },
      "source": [
        "## 1.6 Notes on Adverb Score\n",
        "\n",
        "\n",
        "*   Rescaled new adverb score slightly outperforms the new adverb score without scaling.\n",
        "*   This version computes adverb scores only based on the adverbs that the training algorithm has \"seen.\" Adverbs that the algorithm hasn't seen before are not included in the computation. (Note: we can build algorithms which can address \"unseen\" adverbs if you want.)\n",
        "*   Some job postings ( $\\sim$ 43.5 %) do not contain any adverb, therefore their adverb score is defined as 0.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wD3avqc66Nf"
      },
      "source": [
        "# 2. Gender Score\n",
        "\n",
        "Gender score combines the coefficients of 10 models: 9 of which are from the primary step where female words, male words, and female male words combined are used to fit three different outcomes: overall uptake, male uptake, and female uptake; 1 model is from the secondary step, where we fit a super-learner to combine the results from the above 9 models. The detailed model fitting are provided in the Overleaf documentation. This colab is to guide through the computation. \n",
        "\n",
        "After several precomputation steps, the gender score renders down to the sum of the following four componenets: \n",
        "\n",
        "*   Female word component: a vector of lengh 432 (3 times of the number of female words)\n",
        "*   Male word component: a vector of lengh 474 (3 times of the number of male words \n",
        "*   Intensity component: a vector of length 906 (3 times of all gender words)\n",
        "*   Constant = 0.21 (Intercept from the super-learner)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA5H7HYsYCHc"
      },
      "source": [
        "## 2.1 To compute the female word component, we need the following information: \n",
        "\n",
        "* female word multiplier: provided as f_multiplier in Ongig google drive, Ongig_Colab folder\n",
        "* female word count: the words must be ordered alphabetically, each corresponding word count value is an integer starting from 0\n",
        "* total number of female word: the sum of the total female word\n",
        "\n",
        "Example used here is from job_id = 1094715"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhg5EYjRZYVt",
        "outputId": "04b93ccb-6686-4864-e9ed-bcc8c3deaa3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Ongig/Ongig_Colab\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Ongig/Ongig_Colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IZ8Le1NbTefc"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Let's load everything upfront\n",
        "\n",
        "# These following vectors are used to compute each component of the gender score\n",
        "f_multiplier <- read.csv(\"f_multiplier.csv\")[,\"x\"] # female component\n",
        "m_multiplier <- read.csv(\"m_multiplier.csv\")[,\"x\"] # male component\n",
        "m_f_multiplier <- read.csv(\"m_f_multiplier.csv\")[,\"x\"] # intensity component\n",
        "\n",
        "example <- read.csv(\"job_id_1094715_data.csv\")\n",
        "example_femaleWordCounts <- read.csv(\"job_id_1094715_fwCounts.csv\", row.names = NULL)\n",
        "example_maleWordCounts <- read.csv(\"job_id_1094715_mwCounts.csv\", row.names = NULL)\n",
        "\n",
        "# remove job_id \n",
        "example_femaleWordCounts <- example_femaleWordCounts[,-1]\n",
        "example_maleWordCounts <- example_maleWordCounts[,-1]\n",
        "\n",
        "# combine the female and male words\n",
        "example_genderWordCounts <- cbind(example_maleWordCounts, example_femaleWordCounts)\n",
        "\n",
        "femaleWordCount <- rowSums(example_femaleWordCounts[1,])\n",
        "maleWordCount <- rowSums(example_maleWordCounts[1,])\n",
        "genderWordCount <- rowSums(example_genderWordCounts[1,])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mnAdJrLpZFA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e905a9-a400-423c-e595-2734b71a556c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             [,1]\n",
            "[1,] -0.003023532\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# The most important step is to order the words alphabetically,\n",
        "# so that the coefficients will line up correctly with its corresponding word!\n",
        "\n",
        "example_femaleWordCounts <- example_femaleWordCounts[,order(names(example_femaleWordCounts))]\n",
        "example_femaleWordCounts # now the words should be alphabetically ordered\n",
        "ncol(example_femaleWordCounts)\n",
        "\n",
        "# replicate the wordCounts 3 times\n",
        "# then take the dot product with the f_multiplier\n",
        "# as.numeric function makes sure the values are numeric\n",
        "female_component <- as.numeric(f_multiplier) %*% as.numeric(rep(example_femaleWordCounts[1,],3))\n",
        "female_component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJg0gkMVb_7l"
      },
      "source": [
        "## 2.2 To compute the male word component, we need the following information: \n",
        "\n",
        "* male word multiplier: provided as m_multiplier in Ongig google drive, Ongig_Colab folder\n",
        "* male word count: the words must be ordered alphabetically, each corresponding word count value is an integer starting from 0\n",
        "* total number of male word: the sum of the total male word\n",
        "\n",
        "Example used here is still from job_id = 1094715. Below the calculation is very similar to the calculation we have done above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cThIEKctj7XL",
        "outputId": "9374e029-0015-4c53-b80f-323c56cc0849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              [,1]\n",
            "[1,] -0.0001136762\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# The most important step is to order the words alphabetically,\n",
        "# so that the coefficients will line up correctly with its corresponding word!\n",
        "example_maleWordCounts <- example_maleWordCounts[,order(names(example_maleWordCounts))]\n",
        "\n",
        "# replicate the wordCounts 3 times\n",
        "# then take the dot product with the f_multiplier\n",
        "# as.numeric function makes sure the values are numeric\n",
        "male_component <- as.numeric(m_multiplier) %*% as.numeric(rep(example_maleWordCounts[1,],3))\n",
        "male_component <- male_component / maleWordCount\n",
        "male_component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAkXWgqQmBen"
      },
      "source": [
        "## 2.3 To compute the intensity component, we need the following information: \n",
        "\n",
        "* gender word multiplier: provided as m_f_multiplier in Ongig google drive, Ongig_Colab folder\n",
        "* male and female word count: the words must be ordered alphabetically, each corresponding word count value is an integer starting from 0\n",
        "* total number of gender words: the sum of the total male and female word\n",
        "\n",
        "Example used here is still from job_id = 1094715. Below the calculation is very similar to the calculation we have done above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJbbdz5-qeHi",
        "outputId": "e061bf30-1423-481b-a989-ba1db53c432a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          [,1]\n",
            "[1,] 0.0127578\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "# The most important step is to order the words alphabetically,\n",
        "# so that the coefficients will line up correctly with its corresponding word!\n",
        "example_genderWordCounts <- example_genderWordCounts[,order(names(example_genderWordCounts))]\n",
        "\n",
        "# replicate the wordCounts 3 times\n",
        "# then take the dot product with the f_multiplier\n",
        "# as.numeric function makes sure the values are numeric\n",
        "intensity_component <- as.numeric(m_f_multiplier) %*% as.numeric(rep(example_genderWordCounts[1,],3))\n",
        "intensity_component <- intensity_component / genderWordCount\n",
        "intensity_component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JPNVqOusJ9i"
      },
      "source": [
        "## 2.4 Final step of computing gender score for job_id = 1094715 is to sum up all the components above and add the constant (The constant is the same for all job postings)\n",
        "\n",
        "This result agrees with what we have computed following our algorithm. In the folder \"/content/drive/MyDrive/Ongig/Ongig_Colab/\", you will find a document - \"dfwithFwMw_IdGenderScore.csv\", which contains all the job_id and its precomputed gender score for your reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW--tdH2sQtb",
        "outputId": "717e21dc-ede1-4293-e562-07b89ef33a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          [,1]\n",
            "[1,] 0.2243139\n"
          ]
        }
      ],
      "source": [
        "%%R\n",
        "CONST = 0.2146933\n",
        "\n",
        "gender_score <- female_component + male_component + intensity_component + CONST\n",
        "gender_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpEyy_iKstwl"
      },
      "source": [
        "## 2.5 Discussion\n",
        "\n",
        "* Again, it is very important to order the words before taking the dot product. If words are not ordered, the coefficients will be misaligned with their corresponding word. \n",
        "\n",
        "* This version of the gender score is not scaled, thus the range is not from 0 to 100 yet. Since we are going to use the \"First impression letter grade\" we may just convert the score directly to the letter grade without rescaling to [0, 100]. \n",
        "\n",
        "* The reason I think we may compute the three components (female component, male component, and intensity compoent) separately, then add them up is that then we will have more granular information on your side, especially we think gender score is a high-dimensional scale, thus we may give recommendation depending on certain dimensions. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NQRd_CBI_0do"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}